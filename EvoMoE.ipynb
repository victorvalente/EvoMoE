{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXmZrhF1kaL4dvqoGXbVOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorvalente/EvoMoE/blob/main/EvoMoE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEctbl2FUxU0",
        "outputId": "7b6ea4ea-a5c1-4bbc-def6-420dd3d84d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deap) (2.0.2)\n",
            "Downloading deap-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/135.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/135.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.2\n"
          ]
        }
      ],
      "source": [
        "pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import ast\n",
        "import io\n",
        "import random\n",
        "import re\n",
        "import os # For checking file existence\n",
        "import sys # For potential command-line arguments\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import traceback # For more detailed error logging if needed\n",
        "\n",
        "# Import optimization libraries\n",
        "from deap import base, creator, tools, algorithms\n",
        "# Ensure scipy.optimize is imported for relevant problems\n",
        "from scipy.optimize import minimize, Bounds, LinearConstraint, differential_evolution\n",
        "# Import curve_fit if needed for fitting, though not directly used in basic portfolio opt\n",
        "# from scipy.optimize import curve_fit\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def parse_array_string(arr_str):\n",
        "    \"\"\"Safely parses a string representation of a numpy array.\"\"\"\n",
        "    if not isinstance(arr_str, str) or not arr_str.startswith('array('): return None\n",
        "    try:\n",
        "        processed_str = re.sub(r'\\s+', ' ', arr_str.replace('array(', '', 1).strip())\n",
        "        # Remove trailing ')' if it exists, careful not to remove it from numbers\n",
        "        if processed_str.endswith(')') and '(' not in processed_str.split(')')[-1]: processed_str = processed_str[:-1]\n",
        "        # Add handling for potential 'dtype=' argument if present\n",
        "        processed_str = re.sub(r', dtype=[\\w\\.]+(\\s*|,|\\))', r'\\1', processed_str).strip() # Handle dtype slightly better\n",
        "        if processed_str.endswith(')'): processed_str = processed_str[:-1] # Re-check after dtype removal\n",
        "\n",
        "        list_data = ast.literal_eval(processed_str)\n",
        "        return np.array(list_data)\n",
        "    except Exception as e: print(f\"Warn: Err parsing array: {e}\\nStr: {arr_str[:100]}...\"); return None\n",
        "\n",
        "def parse_problem_data(df, index):\n",
        "    \"\"\"Extracts and parses data for a given problem index.\"\"\"\n",
        "    if index not in df['ProblemIndex'].values: raise ValueError(f\"ProblemIndex {index} not found.\")\n",
        "    problem_row = df.loc[df['ProblemIndex'] == index].iloc[0]\n",
        "    problem_type = problem_row['DetectedType']; description = problem_row['OriginalDescription']\n",
        "    data = {'problem_type': problem_type, 'description': description, 'problem_index': index}\n",
        "    print(f\"\\n--- Parsing Problem Index: {index}, Type: {problem_type} ---\")\n",
        "    for col, value in problem_row.items():\n",
        "        if pd.isna(value) or value == \"\" or col in ['ProblemIndex', 'DetectedType', 'OriginalDescription']: continue\n",
        "        try:\n",
        "            original_value = value; parsed = False; temp_value = value # Use temp_value for parsing attempts\n",
        "\n",
        "            if isinstance(temp_value, str):\n",
        "                 # --- FIX: Strip potential outer quotes added by CSV writer ---\n",
        "                 if len(temp_value) > 1 and temp_value.startswith('\"') and temp_value.endswith('\"'):\n",
        "                     temp_value = temp_value[1:-1].replace('\"\"', '\"') # Remove outer quotes, unescape internal quotes\n",
        "                 # ------------------------------------------------------------\n",
        "\n",
        "                 # ... Debug print for Index 1 ...\n",
        "                 if col == 'list_of_cities' and data.get('problem_index') == 1:\n",
        "                     print(f\"DEBUG(Idx1): Parsing 'list_of_cities'. Post-strip type:{type(temp_value)}, val:{str(temp_value)[:100]}\")\n",
        "                     try: parsed_val_debug = ast.literal_eval(temp_value); print(f\"DEBUG(Idx1): Parsed type:{type(parsed_val_debug)}\")\n",
        "                     except Exception as e_debug: print(f\"DEBUG(Idx1): Failed parse: {e_debug}\")\n",
        "\n",
        "                 # Try parsing complex types using the potentially stripped string\n",
        "                 if (temp_value.startswith('{') and temp_value.endswith('}')) or \\\n",
        "                    (temp_value.startswith('[') and temp_value.endswith(']')):\n",
        "                     try: data[col] = json.loads(temp_value); parsed = True\n",
        "                     except json.JSONDecodeError:\n",
        "                          try:\n",
        "                              if \"__\" in temp_value: print(f\"Warn: Skip ast on unsafe str '{col}'.\")\n",
        "                              else: data[col] = ast.literal_eval(temp_value); parsed = True\n",
        "                          except: pass # Keep parsing attempt order\n",
        "\n",
        "                 if not parsed and temp_value.startswith('array('):\n",
        "                     # Pass the potentially stripped string to array parser\n",
        "                     parsed_array = parse_array_string(temp_value)\n",
        "                     if parsed_array is not None: data[col] = parsed_array; parsed = True\n",
        "\n",
        "                 # Try numeric if not parsed\n",
        "                 numeric_cols = ['investment_amount','num_addresses_expected','num_drivers','num_homes','num_new_shops',\n",
        "                                 'num_nurses','num_rooms','num_sessions','num_shifts','vehicle_mpg','min_distance_miles',\n",
        "                                 'building_stories','max_consecutive_days','minimum_pressure_requirements_at_nodes','num_days']\n",
        "                 if not parsed and col in numeric_cols:\n",
        "                      # Use original value for numeric conversion if stripping quotes wasn't intended? No, use temp_value.\n",
        "                      val_to_convert = temp_value # Use the potentially stripped value\n",
        "                      try: data[col] = float(val_to_convert); parsed = True\n",
        "                      except ValueError:\n",
        "                           try: data[col] = int(val_to_convert); parsed = True\n",
        "                           except ValueError: pass # Keep original value if not parsed\n",
        "\n",
        "                 # Default: store original string if no parsing succeeded\n",
        "                 if not parsed: data[col] = original_value\n",
        "            else:\n",
        "                 data[col] = value # Value wasn't a string initially\n",
        "        except Exception as e: print(f\"Warn: Unhandled parse err '{col}'. Val:'{str(value)[:100]}...'. Err:{e}. Storing str.\"); data[col] = original_value\n",
        "\n",
        "    # Final check for critical fields like num_days\n",
        "    if index == 5 and not isinstance(data.get('num_days'), (int, float)):\n",
        "        print(f\"Parser Check: num_days for Index 5 is '{data.get('num_days')}' after parsing.\")\n",
        "        data['num_days'] = None\n",
        "    return data\n",
        "\n",
        "\n",
        "# --- Objective/Evaluation Functions (remain the same) ---\n",
        "def evaluate_tsp_route(individual, matrix):\n",
        "    distance = 0; n = len(individual)\n",
        "    for i in range(n): distance += matrix[individual[i]][individual[(i + 1) % n]]\n",
        "    return distance\n",
        "def evaluate_knapsack(individual, items_data, capacity):\n",
        "    total_weight, total_value = 0.0, 0.0\n",
        "    for i, item in enumerate(items_data):\n",
        "        if individual[i] == 1: total_weight += item['weight']; total_value += item['value']\n",
        "    return (total_value,) if total_weight <= capacity else (0,)\n",
        "def evaluate_vrp_distance(individual, dist_matrix, num_drivers, depot=0):\n",
        "    total_distance = 0; n_customers = len(individual)\n",
        "    if num_drivers <= 0 : return float('inf'),\n",
        "    customers_per_driver = math.ceil(n_customers / num_drivers)\n",
        "    start_cust_idx = 0; customer_indices = individual[:]\n",
        "    for _ in range(num_drivers):\n",
        "        current_route = [depot]; route_customers = customer_indices[start_cust_idx : start_cust_idx + customers_per_driver]\n",
        "        current_route.extend(route_customers); current_route.append(depot); start_cust_idx += len(route_customers)\n",
        "        route_dist = 0\n",
        "        for i in range(len(current_route) - 1):\n",
        "             from_idx, to_idx = current_route[i], current_route[i+1]\n",
        "             if 0 <= from_idx < dist_matrix.shape[0] and 0 <= to_idx < dist_matrix.shape[1]: route_dist += dist_matrix[from_idx][to_idx]\n",
        "             else: return float('inf'),\n",
        "        total_distance += route_dist\n",
        "        if start_cust_idx >= n_customers: break\n",
        "    return total_distance,\n",
        "def evaluate_facility_location(individual, target_area_bounds, num_demand_points=100):\n",
        "    num_facilities = len(individual) // 2\n",
        "    if num_facilities == 0: return float('inf'),\n",
        "    facility_coords = np.array(individual).reshape(num_facilities, 2)\n",
        "    min_x, max_x, min_y, max_y = target_area_bounds\n",
        "    demand_points = np.random.rand(num_demand_points, 2)\n",
        "    demand_points[:, 0] = demand_points[:, 0] * (max_x - min_x) + min_x\n",
        "    demand_points[:, 1] = demand_points[:, 1] * (max_y - min_y) + min_y\n",
        "    max_dist_overall = 0\n",
        "    for dem_pt in demand_points:\n",
        "        distances = np.linalg.norm(facility_coords - dem_pt, axis=1)\n",
        "        min_dist_to_facility = np.min(distances) if distances.size > 0 else float('inf')\n",
        "        max_dist_overall = max(max_dist_overall, min_dist_to_facility)\n",
        "    return max_dist_overall,\n",
        "def evaluate_nurse_scheduling(individual, num_nurses, num_days, max_consecutive):\n",
        "    if not individual: return float('inf'),\n",
        "    try: schedule = np.array(individual).reshape(num_nurses, num_days)\n",
        "    except ValueError as e: print(f\"Err reshape sched: {e}. Len:{len(individual)}, Exp:({num_nurses},{num_days})\"); return float('inf'),\n",
        "    penalty = 0\n",
        "    for n in range(num_nurses):\n",
        "        consecutive_count = 0\n",
        "        for d in range(num_days):\n",
        "            if schedule[n, d] > 0: consecutive_count += 1\n",
        "            else:\n",
        "                if consecutive_count > max_consecutive: penalty += (consecutive_count - max_consecutive) * 10\n",
        "                consecutive_count = 0\n",
        "        if consecutive_count > max_consecutive: penalty += (consecutive_count - max_consecutive) * 10\n",
        "    return penalty,\n",
        "def portfolio_variance(weights, cov_matrix): return weights @ cov_matrix @ weights\n",
        "def portfolio_return(weights, expected_returns): return np.sum(weights * expected_returns)\n",
        "def evaluate_timetabling(individual, sessions, rooms, slots):\n",
        "    penalty = 0; num_slots, num_sessions, num_rooms = len(slots), len(sessions), len(rooms); room_keys = list(rooms.keys())\n",
        "    if len(individual) != num_sessions: return float('inf'),\n",
        "    schedule_by_slot = defaultdict(list); room_assignments = defaultdict(dict); speakers_in_slot = defaultdict(set); unassigned_sessions = []\n",
        "    for session_idx, slot_idx in enumerate(individual):\n",
        "        if not (0 <= slot_idx < num_slots): return float('inf'),\n",
        "        session_info = sessions[session_idx]\n",
        "        if not isinstance(session_info, dict): return float('inf'),\n",
        "        required_attendance = session_info.get('attendance', 0); speaker = session_info.get('speaker', f'UnknownS_{session_idx}'); assigned_room = False\n",
        "        possible_rooms = random.sample(room_keys, num_rooms)\n",
        "        for room_key in possible_rooms:\n",
        "            room_capacity = rooms.get(room_key, float('inf'))\n",
        "            if not isinstance(room_capacity, (int, float)): room_capacity = float('inf')\n",
        "            if room_key in room_assignments.get(slot_idx, {}): continue\n",
        "            if required_attendance > room_capacity: continue\n",
        "            if speaker in speakers_in_slot.get(slot_idx, set()): continue\n",
        "            schedule_by_slot[slot_idx].append((session_idx, room_key))\n",
        "            if slot_idx not in room_assignments: room_assignments[slot_idx] = {}\n",
        "            room_assignments[slot_idx][room_key] = session_idx\n",
        "            if slot_idx not in speakers_in_slot: speakers_in_slot[slot_idx] = set()\n",
        "            speakers_in_slot[slot_idx].add(speaker); assigned_room = True; break\n",
        "        if not assigned_room: unassigned_sessions.append(session_idx)\n",
        "    penalty += len(unassigned_sessions) * 1000\n",
        "    speakers_check = defaultdict(set)\n",
        "    for slot_idx, assignments in schedule_by_slot.items():\n",
        "        if not isinstance(assignments, list): penalty+=5000; continue\n",
        "        current_speakers = set()\n",
        "        for item in assignments:\n",
        "             if not isinstance(item, tuple) or len(item)!=2: penalty+=5000; continue\n",
        "             session_idx, room_key = item\n",
        "             if not (0 <= session_idx < num_sessions): penalty+=5000; continue\n",
        "             session_info_chk = sessions[session_idx]\n",
        "             if not isinstance(session_info_chk, dict): penalty+=5000; continue\n",
        "             speaker_chk = session_info_chk.get('speaker', f'Unknown_{session_idx}')\n",
        "             if speaker_chk in current_speakers: penalty += 100\n",
        "             current_speakers.add(speaker_chk)\n",
        "    return penalty,\n",
        "def evaluate_project_scheduling(individual, tasks):\n",
        "    task_map = {task['task_id']: i for i, task in enumerate(tasks)}; task_finish_times = {}; max_finish_time = 0; valid_ids = {task['task_id'] for task in tasks}\n",
        "    for task_idx in individual:\n",
        "        task = tasks[task_idx]; task_id = task['task_id']; duration = task['duration_days']; dependencies = task.get('depends_on', []); earliest_start = 0\n",
        "        for dep_id in dependencies:\n",
        "             if dep_id not in valid_ids or dep_id not in task_finish_times: return float('inf'),\n",
        "             earliest_start = max(earliest_start, task_finish_times[dep_id])\n",
        "        finish_time = earliest_start + duration; task_finish_times[task_id] = finish_time; max_finish_time = max(max_finish_time, finish_time)\n",
        "    return max_finish_time,\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "def run_optimization(problem_data, problem_index):\n",
        "    \"\"\"Sets up and runs optimization, returning a results dictionary.\"\"\"\n",
        "    problem_type = problem_data.get('problem_type')\n",
        "    print(f\"\\n>>> Processing Problem Index: {problem_index} ({problem_type}) <<<\")\n",
        "    result = { # Initialize default result\n",
        "        \"ProblemIndex\": problem_index, \"DetectedType\": problem_type, \"Status\": \"Failed - Unknown Error\",\n",
        "        \"ObjectiveValue\": None, \"ObjectiveValue2\": None, \"ResultDetails\": \"\" }\n",
        "\n",
        "    try:\n",
        "        # --- Problem-Specific Porting ---\n",
        "        if problem_type == \"TSP_FLIGHTS\":\n",
        "            print(\"--- Porting TSP_FLIGHTS ---\")\n",
        "            cities=problem_data.get('list_of_cities'); cost_matrix=problem_data.get('flight_cost_matrix'); duration_matrix=problem_data.get('flight_duration_matrix'); transfer_times=problem_data.get('airport_transfer_times_hours')\n",
        "            if not all([isinstance(cities, list), isinstance(cost_matrix, np.ndarray), isinstance(duration_matrix, np.ndarray), isinstance(transfer_times, list)]): result.update({\"Status\": \"Failed - Missing/Invalid Data\", \"ResultDetails\": \"Missing cities, matrices, or transfer times.\"}); return result\n",
        "            num_cities = len(cities)\n",
        "            if cost_matrix.shape!=(num_cities, num_cities) or duration_matrix.shape!=(num_cities, num_cities) or len(transfer_times)!=num_cities: result.update({\"Status\": \"Failed - Data Dimension Mismatch\", \"ResultDetails\": f\"Matrices/times dim mismatch for {num_cities} cities.\"}); return result\n",
        "            print(f\"Data loaded: {num_cities} cities.\")\n",
        "            print(\"=== DEAP Setup (Multi-Obj GA) ===\");\n",
        "            if hasattr(creator, \"FitnessMulti\"): del creator.FitnessMulti\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, -1.0)); creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
        "            toolbox=base.Toolbox(); toolbox.register(\"indices\", random.sample, range(num_cities), num_cities); toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            def evaluate_tsp_flights(individual): tc=evaluate_tsp_route(individual, cost_matrix); td=evaluate_tsp_route(individual, duration_matrix); td += sum(transfer_times[idx] for idx in individual); return tc, td\n",
        "            toolbox.register(\"evaluate\", evaluate_tsp_flights); toolbox.register(\"mate\", tools.cxOrdered); toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05); toolbox.register(\"select\", tools.selNSGA2)\n",
        "            print(\"--- Running DEAP NSGA-II ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 50,50,0.7,0.2; pop=toolbox.population(n=POP_SIZE); hof=tools.ParetoFront();\n",
        "            algorithms.eaMuPlusLambda(pop, toolbox, mu=POP_SIZE, lambda_=POP_SIZE, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results ---\"); print(f\"Non-dom solutions:{len(hof)}\")\n",
        "            if hof: best_sol = hof[0]; fitness = tuple(float(v) for v in best_sol.fitness.values); route_str = ' -> '.join([cities[idx] for idx in best_sol]) + ' -> ' + cities[best_sol[0]]; result.update({\"Status\": \"Success\", \"ObjectiveValue\": fitness[0], \"ObjectiveValue2\": fitness[1], \"ResultDetails\": f\"Found {len(hof)} non-dom solutions. Ex Route: {route_str}; Fit(Cost,Dur):{fitness}\"}); print(f\" Sol 1 (Example): {route_str} | Fit(Cost,Dur):{fitness}\")\n",
        "            else: result.update({\"Status\": \"Success - No Solution Found\", \"ResultDetails\": \"Algorithm finished but HallOfFame is empty.\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"TSP_DRIVING_FUEL\":\n",
        "            print(\"--- Porting TSP_DRIVING_FUEL ---\")\n",
        "            locations=problem_data.get('list_of_cities'); dist_matrix=problem_data.get('driving_distance_matrix_miles'); mpg=problem_data.get('vehicle_mpg')\n",
        "            if not isinstance(locations, list): result.update({\"Status\": \"Failed - Missing/Invalid Data\", \"ResultDetails\": f\"Missing/invalid 'list_of_cities'. Parsed:{locations}. Check CSV.\"}); return result\n",
        "            if not isinstance(dist_matrix, np.ndarray): result.update({\"Status\": \"Failed - Missing/Invalid Data\", \"ResultDetails\": \"Missing/invalid distance matrix (needs actual numpy array).\"}); return result\n",
        "            if not isinstance(mpg,(float,int)) or mpg<=0: result.update({\"Status\": \"Failed - Missing/Invalid Data\", \"ResultDetails\": \"Invalid 'vehicle_mpg'.\"}); return result\n",
        "            num_locations=len(locations);\n",
        "            if dist_matrix.shape!=(num_locations, num_locations): result.update({\"Status\": \"Failed - Data Dimension Mismatch\", \"ResultDetails\": f\"Matrix dim mismatch ({dist_matrix.shape}) for {num_locations} locations.\"}); return result\n",
        "            print(f\"Data loaded: {num_locations} locations, MPG:{mpg}\")\n",
        "            print(\"=== DEAP Setup (GA - Min Fuel) ===\");\n",
        "            if hasattr(creator, \"FitnessMin\"): del creator.FitnessMin\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)); creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "            toolbox=base.Toolbox(); toolbox.register(\"indices\", random.sample, range(num_locations), num_locations); toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            toolbox.register(\"evaluate\", lambda ind: (evaluate_tsp_route(ind, dist_matrix)/mpg,)); toolbox.register(\"mate\", tools.cxOrdered); toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05); toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            print(\"--- Running DEAP GA ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 50,50,0.7,0.2; pop=toolbox.population(n=POP_SIZE); hof=tools.HallOfFame(1);\n",
        "            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results ---\")\n",
        "            if hof: best_ind=hof[0]; route=[locations[idx] for idx in best_ind]; fuel=best_ind.fitness.values[0]; dist=evaluate_tsp_route(best_ind, dist_matrix); route_str = ' -> '.join(route) + ' -> ' + route[0]; result.update({\"Status\": \"Success\", \"ObjectiveValue\": fuel, \"ResultDetails\": f\"Best Route: {route_str} | Fuel:{fuel:.2f}gal, Dist:{dist:.2f}mi\"}); print(f\"Best Route: {route_str} | Fuel:{fuel:.2f}gal, Dist:{dist:.2f}mi\")\n",
        "            else: result.update({\"Status\": \"Success - No Solution Found\", \"ResultDetails\": \"Algorithm finished but HallOfFame is empty.\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"KNAPSACK_MOVING\":\n",
        "            print(\"--- Porting KNAPSACK_MOVING ---\")\n",
        "            items_raw=problem_data.get('item_list_dimensions_values'); truck_dims=problem_data.get('truck_dimensions')\n",
        "            # Add specific type checks after parsing\n",
        "            if not isinstance(items_raw, list): result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid items list. Type:{type(items_raw)}\" }); return result\n",
        "            if not isinstance(truck_dims, list) or len(truck_dims)!=3: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid truck dims. Type:{type(truck_dims)}\" }); return result\n",
        "            items_data=[]; required_keys=['name','width_cm','height_cm','depth_cm','value_usd']\n",
        "            try:\n",
        "                # Check truck_dims content type before conversion\n",
        "                if not all(isinstance(d, (int, float, str)) for d in truck_dims):\n",
        "                     raise TypeError(f\"Truck dimensions list contains non-numeric/non-string types: {truck_dims}\")\n",
        "                truck_volume=np.prod([float(d) for d in truck_dims]); print(f\"Truck Vol:{truck_volume:.0f}cc\"); print(\"Items:\")\n",
        "                for item_dict in items_raw:\n",
        "                    if not isinstance(item_dict, dict) or not all(k in item_dict for k in required_keys): print(f\"Warn: Skip item {item_dict.get('name','N/A') if isinstance(item_dict, dict) else 'Invalid Format'}\"); continue\n",
        "                    vol=float(item_dict['width_cm'])*float(item_dict['height_cm'])*float(item_dict['depth_cm']); val=float(item_dict['value_usd'])\n",
        "                    items_data.append({'name':item_dict['name'],'weight':vol,'value':val}); print(f\"  - {item_dict['name']}: Vol={vol:.0f}, Val=${val:.2f}\")\n",
        "                if not items_data: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"No valid items.\"}); return result\n",
        "                num_items=len(items_data)\n",
        "            except Exception as e: result.update({\"Status\":\"Failed - Data Processing Error\", \"ResultDetails\":f\"Error item/truck data: {e}\"}); return result\n",
        "            print(\"=== DEAP Setup (GA - Max Value) ===\");\n",
        "            if hasattr(creator, \"FitnessMax\"): del creator.FitnessMax\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,)); creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "            toolbox=base.Toolbox(); toolbox.register(\"attr_bool\", random.randint, 0, 1); toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, num_items); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            toolbox.register(\"evaluate\", evaluate_knapsack, items_data=items_data, capacity=truck_volume); toolbox.register(\"mate\", tools.cxTwoPoint); toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05); toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            print(\"--- Running DEAP GA ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 50,40,0.7,0.2; pop=toolbox.population(n=POP_SIZE); hof=tools.HallOfFame(1);\n",
        "            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results ---\")\n",
        "            if hof: best_ind=hof[0]; val=best_ind.fitness.values[0]; vol=sum(items_data[i]['weight'] for i,bit in enumerate(best_ind) if bit==1); items_list=[items_data[i]['name'] for i,bit in enumerate(best_ind) if bit==1] or ['None']; result.update({\"Status\":\"Success\", \"ObjectiveValue\":val, \"ResultDetails\":f\"Volume:{vol:.0f}/{truck_volume:.0f}, Items:{items_list}\"}); print(f\"Best value:${val:.2f}, Vol:{vol:.0f}/{truck_volume:.0f}, Items:{items_list}\")\n",
        "            else: result.update({\"Status\":\"Success - No Solution Found\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"VRP_MANHATTAN\":\n",
        "            print(\"--- Porting VRP_MANHATTAN (Simplified: Min Distance) ---\")\n",
        "            dist_matrix=problem_data.get('driving_distance_matrix_miles'); num_drivers=problem_data.get('num_drivers'); addresses=problem_data.get('delivery_addresses_list')\n",
        "            if not isinstance(dist_matrix, np.ndarray): result.update({\"Status\": \"Failed - Missing Data\", \"ResultDetails\":f\"Requires 'driving_distance_matrix_miles' (Numpy Array). Got type {type(dist_matrix)}. Calc from addrs not implemented.\"}); return result\n",
        "            if not isinstance(num_drivers,(int,float)) or num_drivers<=0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"Invalid 'num_drivers'.\"}); return result\n",
        "            num_drivers=int(num_drivers)\n",
        "            if not isinstance(addresses, list): result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid 'delivery_addresses_list'. Type:{type(addresses)}\" }); return result\n",
        "            num_locations=dist_matrix.shape[0]; num_customers=0; addr_list_offset=0\n",
        "            if num_locations==len(addresses)+1: num_customers=len(addresses); addr_list_offset=1; print(f\"Assume matrix includes depot. {num_customers} cust, {num_drivers} drivers.\")\n",
        "            elif num_locations==len(addresses): num_customers=len(addresses)-1; addr_list_offset=1; print(f\"Assume matrix idx 0=depot. {num_customers} cust, {num_drivers} drivers.\")\n",
        "            else: result.update({\"Status\":\"Failed - Data Dimension Mismatch\", \"ResultDetails\":f\"Matrix/Addr mismatch ({num_locations} vs {len(addresses)}).\"}); return result\n",
        "            if num_customers <= 0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"No customers identified.\"}); return result\n",
        "            print(\"=== DEAP Setup (GA - Min VRP Dist) ===\");\n",
        "            if hasattr(creator, \"FitnessMin\"): del creator.FitnessMin\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)); creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "            toolbox=base.Toolbox(); customer_indices=list(range(1, num_customers+1)); toolbox.register(\"indices\", random.sample, customer_indices, num_customers); toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            toolbox.register(\"evaluate\", evaluate_vrp_distance, dist_matrix=dist_matrix, num_drivers=num_drivers, depot=0); toolbox.register(\"mate\", tools.cxPartialyMatched); toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05); toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            print(\"--- Running DEAP GA ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 60,60,0.7,0.2; pop=toolbox.population(n=POP_SIZE); hof=tools.HallOfFame(1);\n",
        "            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results (Simplified VRP) ---\")\n",
        "            if hof:\n",
        "                 best_ind=hof[0]; min_dist=best_ind.fitness.values[0]; print(f\"Best Total Dist:{min_dist:.2f}\"); result_routes = []\n",
        "                 customers_per_driver=math.ceil(num_customers/num_drivers); start_cust_idx=0; best_cust_order=best_ind[:]\n",
        "                 for d in range(num_drivers):\n",
        "                      route_indices=[0]; route_customers=best_cust_order[start_cust_idx:start_cust_idx+customers_per_driver]; route_indices.extend(route_customers); route_indices.append(0); route_addrs=[]\n",
        "                      for idx in route_indices:\n",
        "                           addr_idx = idx - addr_list_offset\n",
        "                           if idx==0: route_addrs.append(\"DEPOT_0\")\n",
        "                           elif 0<=addr_idx<len(addresses): route_addrs.append(f\"Addr_{idx}({str(addresses[addr_idx])[:15]}...)\")\n",
        "                           else: route_addrs.append(f\"INVALID_IDX_{idx}\")\n",
        "                      route_str = f\"Driver {d+1}: {' -> '.join(route_addrs)}\"\n",
        "                      result_routes.append(route_str); print(route_str)\n",
        "                      start_cust_idx+=len(route_customers);\n",
        "                      if start_cust_idx>=len(best_cust_order): break\n",
        "                 result.update({\"Status\":\"Success\", \"ObjectiveValue\":min_dist, \"ResultDetails\": \"; \".join(result_routes)})\n",
        "            else: result.update({\"Status\":\"Success - No Solution Found\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"FACILITY_LOCATION_SEATTLE\":\n",
        "             print(\"--- Porting FACILITY_LOCATION_SEATTLE (Simplified: Min Max Dist) ---\")\n",
        "             num_shops=problem_data.get('num_new_shops'); min_dist=problem_data.get('min_distance_miles'); target_area=problem_data.get('target_geographic_area')\n",
        "             if not isinstance(num_shops,(int,float)) or num_shops<=0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"Invalid 'num_new_shops'.\"}); return result\n",
        "             num_shops=int(num_shops)\n",
        "             if target_area==\"Seattle\": target_area_bounds=(47.48, 47.73, -122.43, -122.22)\n",
        "             else: print(f\"Warn: No bounds for '{target_area}'. Using generic.\"); target_area_bounds=(0,1,0,1)\n",
        "             print(f\"Data loaded: {num_shops} shops. Area bounds:{target_area_bounds}\")\n",
        "             print(\"=== SciPy Setup (Diff Evolution) ===\"); bounds=[];\n",
        "             for _ in range(num_shops): bounds.extend([(target_area_bounds[2],target_area_bounds[3]), (target_area_bounds[0],target_area_bounds[1])])\n",
        "             objective_func=lambda x: evaluate_facility_location(x, target_area_bounds)[0]\n",
        "             print(\"--- Running SciPy DE ---\")\n",
        "             sci_result=differential_evolution(objective_func, bounds, maxiter=50, popsize=10, disp=False, seed=42)\n",
        "             print(\"--- SciPy Results ---\")\n",
        "             if sci_result.success:\n",
        "                 coords=sci_result.x; score=sci_result.fun; print(f\"Success. Best Score(MinMaxDist):{score:.4f}\"); locations_str_list = []\n",
        "                 print(\"Locations(Lon,Lat):\");\n",
        "                 for i in range(num_shops): loc_str = f\"Shop {i+1}:({coords[i*2]:.5f},{coords[i*2+1]:.5f})\"; locations_str_list.append(loc_str); print(loc_str)\n",
        "                 details = \"; \".join(locations_str_list)\n",
        "                 if min_dist is not None: details += f\" [Note: Min dist constraint ({min_dist}) NOT enforced.]\"; print(f\"Note: Min dist constraint ({min_dist}) NOT enforced.\")\n",
        "                 result.update({\"Status\":\"Success\", \"ObjectiveValue\": score, \"ResultDetails\": details})\n",
        "             else: result.update({\"Status\":\"Failed - Optimization Error\", \"ResultDetails\": f\"SciPy DE failed: {sci_result.message}\"}); print(f\"Optimization failed: {sci_result.message}\")\n",
        "\n",
        "        elif problem_type == \"NURSE_SCHEDULING_MGH\":\n",
        "            print(\"--- Porting NURSE_SCHEDULING_MGH (Simplified: Min Consecutive Penalty) ---\")\n",
        "            num_nurses=problem_data.get('num_nurses'); num_shifts=problem_data.get('num_shifts'); num_days=problem_data.get('num_days'); max_consecutive=problem_data.get('max_consecutive_days')\n",
        "            if num_days is None or not isinstance(num_days,(int,float)) or num_days<=0: result.update({\"Status\":\"Failed - Missing/Invalid Data\", \"ResultDetails\":f\"Invalid 'num_days'. Parsed:{num_days}. Check CSV.\"}); return result\n",
        "            if not isinstance(num_nurses,(int,float)) or num_nurses<=0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"Invalid 'num_nurses'.\"}); return result\n",
        "            if not isinstance(num_shifts,(int,float)) or num_shifts<=0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"Invalid 'num_shifts'.\"}); return result\n",
        "            if not isinstance(max_consecutive,(int,float)) or max_consecutive<=0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"Invalid 'max_consecutive_days'.\"}); return result\n",
        "            num_nurses,num_shifts,num_days,max_consecutive = int(num_nurses),int(num_shifts),int(num_days),int(max_consecutive)\n",
        "            print(f\"Data loaded: {num_nurses} nurses, {num_shifts} work shifts(+1 off), {num_days} days, max {max_consecutive} consecutive.\")\n",
        "            print(\"=== DEAP Setup (GA - Min Penalty) ===\");\n",
        "            if hasattr(creator, \"FitnessMin\"): del creator.FitnessMin\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)); creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "            toolbox=base.Toolbox(); num_possible_shifts=num_shifts+1; toolbox.register(\"attr_shift\", random.randrange, num_possible_shifts); ind_size=num_nurses*num_days; toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_shift, ind_size); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            toolbox.register(\"evaluate\", evaluate_nurse_scheduling, num_nurses=num_nurses, num_days=num_days, max_consecutive=max_consecutive); toolbox.register(\"mate\", tools.cxTwoPoint); toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=num_shifts, indpb=0.02); toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            print(\"--- Running DEAP GA ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 60,70,0.7,0.3; pop=toolbox.population(n=POP_SIZE); hof=tools.HallOfFame(1);\n",
        "            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results (Simplified Nurse Scheduling) ---\")\n",
        "            if hof: best_ind=hof[0]; penalty=best_ind.fitness.values[0]; result.update({\"Status\":\"Success\", \"ObjectiveValue\":penalty, \"ResultDetails\":f\"Best Schedule Penalty:{penalty:.1f}. Note: Only max consecutive days evaluated.\"}); print(f\"Best Schedule Penalty:{penalty:.1f}(Lower=better)\"); print(\"Note: Only max consecutive days evaluated.\")\n",
        "            else: result.update({\"Status\":\"Success - No Solution Found\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"PORTFOLIO_OPTIMIZATION\":\n",
        "            print(\"--- Porting PORTFOLIO_OPTIMIZATION (Simplified: Min Variance) ---\")\n",
        "            assets=problem_data.get('list_of_potential_assets'); hist_perf=problem_data.get('historical_asset_performance_data'); corr_matrix=problem_data.get('asset_correlation_data'); target_return_level=0.10\n",
        "            if not isinstance(assets, list): result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid assets list. Type:{type(assets)}\"}); return result\n",
        "            num_assets = len(assets)\n",
        "            data_status = \"Placeholder Data\"\n",
        "            print(f\"Warn [Idx{problem_index}]: Financial data processing NOT IMPLEMENTED. Using random placeholders.\")\n",
        "            if True: np.random.seed(42); expected_returns=np.random.rand(num_assets)*0.2+0.01; volatilities=np.random.rand(num_assets)*0.3+0.05; _t=np.random.rand(num_assets,num_assets); _c=(_t+_t.T)/2; np.fill_diagonal(_c, 1); D=np.diag(volatilities); cov_matrix=D@_c@D\n",
        "            else: result.update({\"Status\":\"Failed - Not Implemented\", \"ResultDetails\":\"Need to implement financial data processing.\"}); return result\n",
        "            print(f\"Data loaded: {num_assets} assets. Target Return:{target_return_level:.1%}\")\n",
        "            print(\"=== SciPy Setup (QP) ===\"); objective=portfolio_variance; sum_to_one=LinearConstraint(np.ones(num_assets), 1.0, 1.0); ret_constr=LinearConstraint(expected_returns, target_return_level, np.inf); bounds=Bounds(0.0, 1.0); constraints=[sum_to_one, ret_constr]; init_w=np.ones(num_assets)/num_assets\n",
        "            print(\"--- Running SciPy Optimizer (SLSQP) ---\")\n",
        "            sci_result=minimize(objective, init_w, args=(cov_matrix,), method='SLSQP', bounds=bounds, constraints=constraints, options={'disp': False, 'ftol': 1e-9})\n",
        "            print(\"--- SciPy Results ---\")\n",
        "            if sci_result.success: weights=sci_result.x; ret=portfolio_return(weights, expected_returns); var=sci_result.fun; vol=np.sqrt(var); print(f\"Success. Return={ret:.2%}, Volatility={vol:.2%}\"); weights_str_list=[]; print(\"Weights:\"); [ (weights_str_list.append(f\"{asset}:{weights[i]:.2%}\"), print(f\"    - {asset}: {weights[i]:.2%}\")) for i, asset in enumerate(assets) if weights[i]>1e-4] ; result.update({\"Status\":\"Success\", \"ObjectiveValue\":vol, \"ObjectiveValue2\":ret, \"ResultDetails\": f\"Data: {data_status}. Weights: {'; '.join(weights_str_list)}\"})\n",
        "            else: result.update({\"Status\":\"Failed - Optimization Error\", \"ResultDetails\": f\"SciPy SLSQP failed: {sci_result.message}\"}); print(f\"Optimization failed: {sci_result.message}\")\n",
        "\n",
        "        elif problem_type == \"TIMETABLING_CONFERENCE\":\n",
        "            print(\"--- Porting TIMETABLING_CONFERENCE (Simplified: Min Clashes) ---\")\n",
        "            sessions_raw=problem_data.get('list_of_sessions_with_topics_speakers'); rooms_raw=problem_data.get('list_of_rooms_with_capacities'); slots_per_day=problem_data.get('timeslots_per_day'); num_days=problem_data.get('num_days')\n",
        "            if not isinstance(sessions_raw, list): result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid sessions list. Type:{type(sessions_raw)}\" }); return result\n",
        "            if not isinstance(rooms_raw, list): result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid rooms list. Type:{type(rooms_raw)}\" }); return result\n",
        "            if not isinstance(slots_per_day, list): result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid timeslots list. Type:{type(slots_per_day)}\" }); return result\n",
        "            if not isinstance(num_days,(int,float)) or num_days<=0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"Invalid num_days.\"}); return result\n",
        "            num_days=int(num_days); num_slots_total=len(slots_per_day)*num_days; rooms={r['room_name']:r.get('capacity',float('inf')) for r in rooms_raw if 'room_name' in r}; num_rooms=len(rooms);\n",
        "            if num_rooms==0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"No valid rooms.\"}); return result\n",
        "            slots=list(range(num_slots_total)); avg_cap=sum(v for v in rooms.values() if isinstance(v,(int,float)))/num_rooms if num_rooms else 50\n",
        "            sessions = [];\n",
        "            for i, s in enumerate(sessions_raw):\n",
        "                if isinstance(s, dict): s.setdefault('attendance', int(avg_cap/2)); sessions.append(s)\n",
        "                else: print(f\"Warn: Session data at index {i} not dict: {s}. Skipping.\")\n",
        "            num_sessions = len(sessions)\n",
        "            if num_sessions == 0: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"No valid sessions.\"}); return result\n",
        "            print(f\"Data loaded: {num_sessions} sessions, {num_rooms} rooms, {num_slots_total} slots.\")\n",
        "            print(\"=== DEAP Setup (GA - Min Penalty) ===\");\n",
        "            if hasattr(creator, \"FitnessMin\"): del creator.FitnessMin\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)); creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "            toolbox=base.Toolbox(); toolbox.register(\"attr_slot\", random.randrange, num_slots_total); toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_slot, num_sessions); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            toolbox.register(\"evaluate\", evaluate_timetabling, sessions=sessions, rooms=rooms, slots=slots); toolbox.register(\"mate\", tools.cxUniform, indpb=0.5); toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=num_slots_total-1, indpb=0.05); toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            print(\"--- Running DEAP GA ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 60,80,0.7,0.3; pop=toolbox.population(n=POP_SIZE); hof=tools.HallOfFame(1);\n",
        "            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results (Simplified Timetabling) ---\")\n",
        "            if hof: best_ind=hof[0]; penalty=best_ind.fitness.values[0]; result.update({\"Status\":\"Success\", \"ObjectiveValue\":penalty, \"ResultDetails\":f\"Best Schedule Penalty:{penalty:.1f}. Note: Basic constraints only.\"}); print(f\"Best Schedule Penalty:{penalty:.1f}(Lower=better)\"); print(\"Note: Only basic speaker/room/capa evaluated.\")\n",
        "            else: result.update({\"Status\":\"Success - No Solution Found\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"PROJECT_SCHEDULING_CONSTRUCTION\":\n",
        "            print(\"--- Porting PROJECT_SCHEDULING_CONSTRUCTION (Simplified: Min Makespan) ---\")\n",
        "            tasks_raw=problem_data.get('list_of_tasks_with_durations_and_dependencies')\n",
        "            if not isinstance(tasks_raw, list) or not tasks_raw: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":f\"Invalid tasks list. Type:{type(tasks_raw)}\" }); return result\n",
        "            tasks=[]; valid_ids=set(); required_keys=['task_id','duration_days']\n",
        "            try:\n",
        "                 for task_dict in tasks_raw:\n",
        "                      if not all(k in task_dict for k in required_keys): print(f\"Warn: Skip task {task_dict.get('task_id','N/A')}\"); continue\n",
        "                      task_dict['duration_days']=float(task_dict['duration_days']); task_dict.setdefault('depends_on', [])\n",
        "                      if task_dict['duration_days']<0: print(f\"Warn: Task {task_dict['task_id']} neg duration.\"); continue\n",
        "                      tasks.append(task_dict); valid_ids.add(task_dict['task_id'])\n",
        "                 if not tasks: result.update({\"Status\":\"Failed - Invalid Data\", \"ResultDetails\":\"No valid tasks.\"}); return result\n",
        "                 num_tasks=len(tasks);\n",
        "                 for task in tasks: task['depends_on']=[dep for dep in task['depends_on'] if dep in valid_ids]\n",
        "            except Exception as e: result.update({\"Status\":\"Failed - Data Processing Error\", \"ResultDetails\":f\"Error task data: {e}\"}); return result\n",
        "            print(f\"Data loaded: {num_tasks} valid tasks.\")\n",
        "            print(\"=== DEAP Setup (GA - Min Makespan) ===\");\n",
        "            if hasattr(creator, \"FitnessMin\"): del creator.FitnessMin\n",
        "            if hasattr(creator, \"Individual\"): del creator.Individual\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,)); creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "            toolbox=base.Toolbox(); toolbox.register(\"indices\", random.sample, range(num_tasks), num_tasks); toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices); toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "            toolbox.register(\"evaluate\", evaluate_project_scheduling, tasks=tasks); toolbox.register(\"mate\", tools.cxOrdered); toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05); toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            print(\"--- Running DEAP GA ---\"); POP_SIZE,MAX_GEN,CXPB,MUTPB = 50,60,0.7,0.2; pop=toolbox.population(n=POP_SIZE); hof=tools.HallOfFame(1);\n",
        "            algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=MAX_GEN, halloffame=hof, verbose=False)\n",
        "            print(\"--- DEAP Results (Simplified Proj Sched) ---\")\n",
        "            if hof: best_ind=hof[0]; makespan=best_ind.fitness.values[0]; task_seq=[tasks[idx]['task_id'] for idx in best_ind]; seq_str = ' -> '.join(task_seq); result.update({\"Status\":\"Success\", \"ObjectiveValue\":makespan, \"ResultDetails\":f\"Makespan:{makespan:.1f}days. Sequence: {seq_str}. Note: Resources NOT considered.\"}); print(f\"Best Makespan:{makespan:.1f}days\"); print(f\"  Sequence: {seq_str}\"); print(\"Note: Resources NOT considered.\")\n",
        "            else: result.update({\"Status\":\"Success - No Solution Found\"}); print(\"No solution found.\")\n",
        "\n",
        "        elif problem_type == \"NETWORK_DESIGN_WATER\":\n",
        "            print(\"--- Porting NETWORK_DESIGN_WATER (Conceptual Placeholder) ---\")\n",
        "            num_homes=problem_data.get('num_homes'); pipe_types=problem_data.get('pipe_types_and_costs_per_unit_length_per_diameter')\n",
        "            print(\"Warn: Water network design requires external data & simulation.\"); details = \"Requires external data/simulation.\"\n",
        "            if isinstance(pipe_types, list) and pipe_types:\n",
        "                 print(\"Pipe Types(Ex):\"); [print(f\"  - {pt}\") for pt in pipe_types[:3]]\n",
        "                 print(\"\\n=== Conceptual Setup ===\"); print(\"Obj: Min pipe cost (conceptual)\")\n",
        "                 assumed_len=float(num_homes)*50 if num_homes and isinstance(num_homes, (int, float)) else 5000 # Added check for num_homes type\n",
        "                 cheap_pipe=min(pipe_types, key=lambda x: x.get('cost_per_meter', float('inf')))\n",
        "                 cost = cheap_pipe.get('cost_per_meter', 0) * assumed_len if isinstance(cheap_pipe.get('cost_per_meter'), (int, float)) else 0 # Added check for cost type\n",
        "                 details = f\"Conceptual min cost({assumed_len:.0f}m): ${cost:.2f}. Requires simulation.\"\n",
        "                 print(f\"Simplistic Min Cost({assumed_len:.0f}m): ${cost:.2f}\"); print(\"Result: Cannot perform valid optimization.\")\n",
        "            else: print(\"Pipe data missing/invalid.\"); details += \" Pipe data missing.\"\n",
        "            print(\"--- Results: Skipped ---\")\n",
        "            result.update({\"Status\":\"Skipped - Conceptual Only\", \"ResultDetails\": details})\n",
        "\n",
        "        else:\n",
        "            details = f\"Optimization logic for type '{problem_type}' is not implemented.\"\n",
        "            print(details)\n",
        "            result.update({\"Status\": \"Failed - Not Implemented\", \"ResultDetails\": details})\n",
        "\n",
        "    except Exception as e:\n",
        "        err_details = f\"Runtime Error in run_optimization: {type(e).__name__} - {e}\"\n",
        "        print(err_details); # traceback.print_exc() # Uncomment for full traceback\n",
        "        result.update({\"Status\": \"Failed - Execution Error\", \"ResultDetails\": err_details})\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- Script Entry Point ---\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"problems_data_structured_manual.csv\" # Make sure this matches your filename\n",
        "    results_file_path = \"optimization_results.csv\"\n",
        "    indices_to_run = None\n",
        "    all_results = [] # List to store result dictionaries\n",
        "\n",
        "    if len(sys.argv) > 1:\n",
        "        try: indices_to_run = [int(arg) for arg in sys.argv[1:]]; print(f\"Running only indices: {indices_to_run}\")\n",
        "        except ValueError: print(\"Warn: Args not integers. Running all.\"); indices_to_run = None\n",
        "\n",
        "    if not os.path.exists(file_path): print(f\"Error: File not found '{file_path}'\"); sys.exit(1)\n",
        "    print(f\"Loading data from '{file_path}'...\")\n",
        "    try: df = pd.read_csv(file_path, dtype=str) # Read all as string initially\n",
        "    except Exception as e: print(f\"Error loading CSV '{file_path}': {e}\"); sys.exit(1)\n",
        "    if 'ProblemIndex' not in df.columns or 'DetectedType' not in df.columns: print(f\"Error: Required columns missing.\"); sys.exit(1)\n",
        "\n",
        "    try: df['ProblemIndex'] = df['ProblemIndex'].astype(int) # Convert index col to int\n",
        "    except ValueError: print(\"Error: ProblemIndex column non-integer.\"); sys.exit(1)\n",
        "\n",
        "    all_indices = sorted(df['ProblemIndex'].unique()); target_indices = indices_to_run if indices_to_run is not None else all_indices\n",
        "    processed_count = 0\n",
        "\n",
        "    for index in target_indices:\n",
        "        if index not in all_indices: print(f\"Warn: Index {index} not in file. Skipping.\"); continue\n",
        "        print(f\"\\n{'='*20} Processing Problem Index: {index} {'='*20}\")\n",
        "        current_result = { # Default result\n",
        "                \"ProblemIndex\": index, \"DetectedType\": \"Unknown\", \"Status\": \"Failed - Parsing Error\",\n",
        "                \"ObjectiveValue\": None, \"ObjectiveValue2\": None, \"ResultDetails\": \"Error before run_optimization call\" }\n",
        "        try:\n",
        "            problem_data = parse_problem_data(df, index)\n",
        "            current_result[\"DetectedType\"] = problem_data.get('problem_type', 'Unknown')\n",
        "            current_result[\"Status\"] = \"Processing\"\n",
        "            run_result = run_optimization(problem_data, index)\n",
        "            current_result.update(run_result)\n",
        "            processed_count += 1\n",
        "        except ValueError as e: current_result.update({\"Status\": \"Failed - Config Error\", \"ResultDetails\": str(e)})\n",
        "        except KeyError as e: current_result.update({\"Status\": \"Failed - Missing Data Error\", \"ResultDetails\": f\"Key '{e}' not found\"})\n",
        "        except Exception as e:\n",
        "             err_msg = f\"Runtime Error before/during run_opt: {type(e).__name__} - {e}\"\n",
        "             print(err_msg); # traceback.print_exc()\n",
        "             current_result.update({\"Status\": \"Failed - Runtime Error\", \"ResultDetails\": err_msg})\n",
        "        finally:\n",
        "            all_results.append(current_result)\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "    print(f\"\\n>>> Processing Complete <<<\")\n",
        "    print(f\"Total problems attempted: {len(target_indices)}\")\n",
        "    print(f\"Loop Iterations Completed: {processed_count}\")\n",
        "    status_counts = defaultdict(int) # Corrected loop\n",
        "    for res in all_results:\n",
        "        status_counts[res.get(\"Status\", \"Unknown Status\")] += 1\n",
        "    print(\"Final Status Counts:\");\n",
        "    for status, count in status_counts.items(): print(f\"  - {status}: {count}\")\n",
        "\n",
        "    if all_results:\n",
        "        try:\n",
        "            print(f\"\\nSaving results to '{results_file_path}'...\")\n",
        "            df_results = pd.DataFrame(all_results)\n",
        "            cols_order = [\"ProblemIndex\", \"DetectedType\", \"Status\", \"ObjectiveValue\", \"ObjectiveValue2\", \"ResultDetails\"]\n",
        "            df_results = df_results[[col for col in cols_order if col in df_results.columns]]\n",
        "            df_results.to_csv(results_file_path, index=False, encoding='utf-8')\n",
        "            print(\"Results saved successfully.\")\n",
        "        except Exception as e: print(f\"Error saving results to CSV: {e}\")\n",
        "    else: print(\"No results were generated to save.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeueBntdVA5L",
        "outputId": "82e7ee51-4c62-42e0-b94e-5bfcdcdd7625"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warn: Args not integers. Running all.\n",
            "Loading data from 'problems_data_structured_manual.csv'...\n",
            "\n",
            "==================== Processing Problem Index: 0 ====================\n",
            "\n",
            "--- Parsing Problem Index: 0, Type: TSP_FLIGHTS ---\n",
            "\n",
            ">>> Processing Problem Index: 0 (TSP_FLIGHTS) <<<\n",
            "--- Porting TSP_FLIGHTS ---\n",
            "Data loaded: 10 cities.\n",
            "=== DEAP Setup (Multi-Obj GA) ===\n",
            "--- Running DEAP NSGA-II ---\n",
            "--- DEAP Results ---\n",
            "Non-dom solutions:9\n",
            " Sol 1 (Example): Amsterdam -> Berlin -> Budapest -> Paris -> London -> Madrid -> Barcelona -> Prague -> Vienna -> Rome -> Amsterdam | Fit(Cost,Dur):(2882.77261225, 69.04980647000001)\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 1 ====================\n",
            "\n",
            "--- Parsing Problem Index: 1, Type: TSP_DRIVING_FUEL ---\n",
            "DEBUG(Idx1): Parsing 'list_of_cities'. Post-strip type:<class 'str'>, val:[\"Yellowstone\", \"Yosemite\", \"Zion\", \"Olympic\", \"Glacier\", \"Acadia\", \"Teton\", \"Rocky Mountain\"]\n",
            "DEBUG(Idx1): Parsed type:<class 'list'>\n",
            "\n",
            ">>> Processing Problem Index: 1 (TSP_DRIVING_FUEL) <<<\n",
            "--- Porting TSP_DRIVING_FUEL ---\n",
            "Data loaded: 8 locations, MPG:25.0\n",
            "=== DEAP Setup (GA - Min Fuel) ===\n",
            "--- Running DEAP GA ---\n",
            "--- DEAP Results ---\n",
            "Best Route: Olympic -> Zion -> Yellowstone -> Acadia -> Rocky Mountain -> Yosemite -> Teton -> Glacier -> Olympic | Fuel:250.76gal, Dist:6268.96mi\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 2 ====================\n",
            "\n",
            "--- Parsing Problem Index: 2, Type: KNAPSACK_MOVING ---\n",
            "\n",
            ">>> Processing Problem Index: 2 (KNAPSACK_MOVING) <<<\n",
            "--- Porting KNAPSACK_MOVING ---\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 3 ====================\n",
            "\n",
            "--- Parsing Problem Index: 3, Type: VRP_MANHATTAN ---\n",
            "\n",
            ">>> Processing Problem Index: 3 (VRP_MANHATTAN) <<<\n",
            "--- Porting VRP_MANHATTAN (Simplified: Min Distance) ---\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 4 ====================\n",
            "\n",
            "--- Parsing Problem Index: 4, Type: FACILITY_LOCATION_SEATTLE ---\n",
            "\n",
            ">>> Processing Problem Index: 4 (FACILITY_LOCATION_SEATTLE) <<<\n",
            "--- Porting FACILITY_LOCATION_SEATTLE (Simplified: Min Max Dist) ---\n",
            "Data loaded: 7 shops. Area bounds:(47.48, 47.73, -122.43, -122.22)\n",
            "=== SciPy Setup (Diff Evolution) ===\n",
            "--- Running SciPy DE ---\n",
            "--- SciPy Results ---\n",
            "Success. Best Score(MinMaxDist):240.2908\n",
            "Locations(Lon,Lat):\n",
            "Shop 1:(-122.38337,47.54458)\n",
            "Shop 2:(-122.29512,47.61120)\n",
            "Shop 3:(-122.23211,47.49156)\n",
            "Shop 4:(-122.23062,47.70074)\n",
            "Shop 5:(-122.30748,47.56859)\n",
            "Shop 6:(-122.31619,47.71436)\n",
            "Shop 7:(-122.22467,47.52397)\n",
            "Note: Min dist constraint (0.5) NOT enforced.\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 5 ====================\n",
            "\n",
            "--- Parsing Problem Index: 5, Type: NURSE_SCHEDULING_MGH ---\n",
            "\n",
            ">>> Processing Problem Index: 5 (NURSE_SCHEDULING_MGH) <<<\n",
            "--- Porting NURSE_SCHEDULING_MGH (Simplified: Min Consecutive Penalty) ---\n",
            "Data loaded: 25 nurses, 3 work shifts(+1 off), 14 days, max 5 consecutive.\n",
            "=== DEAP Setup (GA - Min Penalty) ===\n",
            "--- Running DEAP GA ---\n",
            "--- DEAP Results (Simplified Nurse Scheduling) ---\n",
            "Best Schedule Penalty:0.0(Lower=better)\n",
            "Note: Only max consecutive days evaluated.\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 6 ====================\n",
            "\n",
            "--- Parsing Problem Index: 6, Type: PORTFOLIO_OPTIMIZATION ---\n",
            "\n",
            ">>> Processing Problem Index: 6 (PORTFOLIO_OPTIMIZATION) <<<\n",
            "--- Porting PORTFOLIO_OPTIMIZATION (Simplified: Min Variance) ---\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 7 ====================\n",
            "\n",
            "--- Parsing Problem Index: 7, Type: TIMETABLING_CONFERENCE ---\n",
            "\n",
            ">>> Processing Problem Index: 7 (TIMETABLING_CONFERENCE) <<<\n",
            "--- Porting TIMETABLING_CONFERENCE (Simplified: Min Clashes) ---\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 8 ====================\n",
            "\n",
            "--- Parsing Problem Index: 8, Type: PROJECT_SCHEDULING_CONSTRUCTION ---\n",
            "\n",
            ">>> Processing Problem Index: 8 (PROJECT_SCHEDULING_CONSTRUCTION) <<<\n",
            "--- Porting PROJECT_SCHEDULING_CONSTRUCTION (Simplified: Min Makespan) ---\n",
            "------------------------------------------------------------\n",
            "\n",
            "==================== Processing Problem Index: 9 ====================\n",
            "\n",
            "--- Parsing Problem Index: 9, Type: NETWORK_DESIGN_WATER ---\n",
            "\n",
            ">>> Processing Problem Index: 9 (NETWORK_DESIGN_WATER) <<<\n",
            "--- Porting NETWORK_DESIGN_WATER (Conceptual Placeholder) ---\n",
            "Warn: Water network design requires external data & simulation.\n",
            "Pipe data missing/invalid.\n",
            "--- Results: Skipped ---\n",
            "------------------------------------------------------------\n",
            "\n",
            ">>> Processing Complete <<<\n",
            "Total problems attempted: 10\n",
            "Loop Iterations Completed: 10\n",
            "Final Status Counts:\n",
            "  - Success: 4\n",
            "  - Failed - Invalid Data: 5\n",
            "  - Skipped - Conceptual Only: 1\n",
            "\n",
            "Saving results to 'optimization_results.csv'...\n",
            "Results saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JuKZ3H1YnT-R"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}